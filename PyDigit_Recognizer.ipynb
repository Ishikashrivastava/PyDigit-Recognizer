{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MsVTlMZfUSam"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "Xy09nLEsCdDA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=datasets.MNIST(\n",
        "    root = \"data\",\n",
        "    train=True,\n",
        "    transform = ToTensor(),\n",
        "    download= True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hvY2VnYbaVY",
        "outputId": "363d6b29-5b9f-4817-bd7c-06ceb68924f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 16143318.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 476499.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4361417.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4413931.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llZa7u_KbgMY",
        "outputId": "0659e3fa-cf36-4b4a-c073-09e91d564cfb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=datasets.MNIST(\n",
        "    root = \"data\",\n",
        "    train=False,\n",
        "    transform = ToTensor(),\n",
        "    download= True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "9yahJE-lbp1N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IcRwBphc4Cq",
        "outputId": "9e2a8cb5-4bef-4810-fb48-d14e0dcbac98"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VGpGmcZc6-y",
        "outputId": "8aef17f7-b24a-4383-d41d-740d98c2dbd8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFf8k2DHdDUQ",
        "outputId": "7b940128-7f50-4519-cb80-9c3fba052160"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loaders ={\n",
        "    \"train\":DataLoader(train_data,\n",
        "                       batch_size=100,\n",
        "                       shuffle=True,\n",
        "                       num_workers=1),\n",
        "    \"test\":DataLoader(test_data,\n",
        "                      batch_size=100,\n",
        "                      shuffle=True,\n",
        "                      num_workers=1)\n",
        "}\n"
      ],
      "metadata": {
        "id": "UqHO4-ABjN4k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDIoT7Zoj7nM",
        "outputId": "31899370-4d5a-49a9-abc4-e3015ab9c1c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7bada6df3730>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7bada6df3580>}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# most important we want to find a particular deeep learning model!\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(CNN,self).__init__()\n",
        "\n",
        "      self.conv1=nn.Conv2d(1,10,kernel_size=5)\n",
        "      self.conv2=nn.Conv2d(10,20,kernel_size=5)\n",
        "      self.conv2_drop=nn.Dropout2d()\n",
        "      self.fc1=nn.Linear(320,50)\n",
        "      self.fc2=nn.Linear(50,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x=F.relu(F.max_pool2d(self.conv1(x),2))\n",
        "      x=F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
        "      x=x.view(-1,320) # it is to show flateen of daya so we use view\n",
        "      x=F.relu(self.fc1(x))\n",
        "      x=F.dropout(x,training=self.training)\n",
        "      x=self.fc2(x)\n",
        "\n",
        "      return F.softmax(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L5AhNbFok7Em"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx,(data,target) in enumerate(loaders[\"train\"]):\n",
        "    data,target=data.to(device),target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output=model(data)\n",
        "    loss=loss_fn(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 20 == 0:\n",
        "      print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100. * batch_idx / len(loaders['train']):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad(): # Use the correct torch.no_grad() function\n",
        "    for data, target in loaders['test']:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target).item()\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'].dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "      test_loss, correct, len(loaders['test'].dataset),\n",
        "      100. * correct / len(loaders['test'].dataset)))"
      ],
      "metadata": {
        "id": "nBJiEHTB9OVE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,10):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m25mcB4e9Wc_",
        "outputId": "57987e36-a26d-46f1-dc66-b807ee9b4370"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-34d9fef67d6e>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301939\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.280079\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.138229\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.908129\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.905544\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.841179\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.789033\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.853426\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.804841\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.701788\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.703723\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.732982\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.686454\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.733663\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.677666\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.666697\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.651044\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.714327\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 1.581550\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 1.659911\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.653700\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.604461\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.654138\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 1.625053\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.585514\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.613652\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 1.569613\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 1.644471\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.595325\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 1.600148\n",
            "\n",
            "Test set: Average loss: 0.0153, Accuracy: 9349/10000 (93%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.663789\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 1.600573\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 1.642389\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 1.608002\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.636658\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.633487\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.611330\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 1.592240\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.581564\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 1.600170\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.656066\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 1.625315\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.590672\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 1.574008\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.607435\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.544065\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.593644\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.611100\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.562697\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.561035\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.614342\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.639796\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.549800\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.592320\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.605650\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.602857\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.588609\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.580488\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.579650\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.537023\n",
            "\n",
            "Test set: Average loss: 0.0151, Accuracy: 9545/10000 (95%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.570777\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.604845\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.528714\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.570240\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.592659\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.604493\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.579566\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.539096\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.647519\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.519639\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.577437\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.562190\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.560979\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.601650\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.616160\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.565975\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.591239\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.577958\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.611654\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.552594\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.629855\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.563285\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.557773\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.557745\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.532807\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.530490\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.556479\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.520312\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.581577\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.528349\n",
            "\n",
            "Test set: Average loss: 0.0150, Accuracy: 9568/10000 (96%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.554917\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.556521\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.596853\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.619204\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.523930\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.550812\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.529847\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.555214\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.573318\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.528891\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.562678\n",
            "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.548739\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.581545\n",
            "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.566196\n",
            "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.554931\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.528196\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.515581\n",
            "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.518264\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.551690\n",
            "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.534377\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.523677\n",
            "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 1.553962\n",
            "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.537977\n",
            "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 1.527160\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.514017\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 1.620788\n",
            "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 1.530457\n",
            "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 1.585823\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 1.528491\n",
            "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 1.502009\n",
            "\n",
            "Test set: Average loss: 0.0150, Accuracy: 9637/10000 (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.558361\n",
            "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 1.540951\n",
            "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 1.548668\n",
            "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 1.539746\n",
            "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 1.568094\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 1.514323\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 1.554098\n",
            "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 1.571710\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.546240\n",
            "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 1.520684\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 1.538707\n",
            "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 1.532861\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 1.533800\n",
            "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 1.536989\n",
            "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 1.566894\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 1.516503\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.598053\n",
            "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 1.559256\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 1.541345\n",
            "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 1.537349\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 1.524567\n",
            "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 1.540357\n",
            "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 1.527630\n",
            "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 1.533793\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.540223\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 1.521211\n",
            "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 1.583164\n",
            "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 1.523456\n",
            "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 1.548482\n",
            "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 1.572367\n",
            "\n",
            "Test set: Average loss: 0.0150, Accuracy: 9662/10000 (97%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.507740\n",
            "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 1.539135\n",
            "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 1.534687\n",
            "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 1.569214\n",
            "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 1.535123\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 1.558530\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 1.561781\n",
            "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 1.533602\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 1.532513\n",
            "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 1.564104\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 1.607029\n",
            "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 1.522518\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 1.574631\n",
            "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 1.516795\n",
            "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 1.509662\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 1.550089\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.509834\n",
            "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 1.570470\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 1.529692\n",
            "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 1.551063\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 1.501416\n",
            "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 1.541909\n",
            "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 1.542524\n",
            "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 1.517722\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 1.535809\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 1.524580\n",
            "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 1.500397\n",
            "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 1.504044\n",
            "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 1.535168\n",
            "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 1.563137\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9695/10000 (97%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.487366\n",
            "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 1.536309\n",
            "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 1.566350\n",
            "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 1.557831\n",
            "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 1.565180\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 1.542845\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 1.589706\n",
            "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 1.531584\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 1.549751\n",
            "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 1.535643\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 1.560298\n",
            "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 1.536631\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 1.547144\n",
            "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 1.529879\n",
            "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 1.579545\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 1.533212\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.554387\n",
            "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 1.558824\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 1.547697\n",
            "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 1.527967\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 1.511375\n",
            "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 1.518668\n",
            "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 1.539258\n",
            "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 1.544805\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 1.548118\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 1.562925\n",
            "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 1.536348\n",
            "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 1.500396\n",
            "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 1.528009\n",
            "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 1.520676\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9697/10000 (97%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.552005\n",
            "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 1.557501\n",
            "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 1.531771\n",
            "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 1.537290\n",
            "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 1.596352\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 1.547833\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 1.542324\n",
            "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 1.550888\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 1.587636\n",
            "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 1.563397\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 1.522901\n",
            "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 1.527688\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 1.534141\n",
            "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 1.534075\n",
            "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 1.494526\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 1.493885\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.510268\n",
            "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 1.503976\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 1.524604\n",
            "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 1.577481\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 1.511422\n",
            "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 1.535142\n",
            "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 1.549512\n",
            "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 1.531557\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 1.505743\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 1.536772\n",
            "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 1.501809\n",
            "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 1.552340\n",
            "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 1.508865\n",
            "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 1.553380\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9715/10000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.515403\n",
            "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 1.537416\n",
            "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 1.516710\n",
            "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 1.539467\n",
            "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 1.545814\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 1.528639\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 1.517777\n",
            "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 1.518461\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.604450\n",
            "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 1.517639\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 1.496937\n",
            "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 1.606107\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 1.600389\n",
            "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 1.554427\n",
            "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 1.545032\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 1.512738\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.537287\n",
            "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 1.521319\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 1.555552\n",
            "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 1.523444\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 1.550394\n",
            "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 1.528181\n",
            "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 1.505859\n",
            "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 1.533539\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 1.543631\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 1.555478\n",
            "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 1.514670\n",
            "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 1.498816\n",
            "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 1.555241\n",
            "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 1.545627\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9737/10000 (97%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btEvAhnu9yuG",
        "outputId": "587bd784-ec0f-4dba-bc42-d2afa4f70925"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model.eval()\n",
        "data,target = test_data[20]\n",
        "data=data.unsqueeze(0).to(device)\n",
        "output=model(data)\n",
        "# Use .item() to get the value of a single-element tensor\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "print(f\"Predicted: {prediction}\")\n",
        "image=data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "plt.imshow(image,cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "81K-JCVZAZU1",
        "outputId": "3005fc29-be1c-4703-90cf-357a64f9666b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-34d9fef67d6e>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}